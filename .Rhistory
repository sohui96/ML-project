final_mg <- spread(mg, key = "genres", value = "value", fill = NA)
final_mg <- final_mg[,-c(1,2)]
# Chunk 9
knitr::kable(head(mg))
knitr::kable(table(mg$genres))
df2 <- as(final_mg, 'matrix')
df2 <- as(df2, 'realRatingMatrix')
# Chunk 10
set.seed(2021)
index <- sample(1:nrow(df2), size = nrow(df2)*0.7)
train <- df2[index, ]
test  <- df2[-index,]
model1 <- Recommender(train, method = "IBCF")
model1
pre <- predict(model1, newdata=test[1], n=10) #test 1 ~ 183
# as(pre, "list")
# just check
pre_list <- sapply(pre@items, function(x) {colnames(train)[x]})
table(unlist(lapply(pre_list, length)))
knitr::kable(pre_list[])
# 데이터 조정 후 재학습
table(rowCounts(df2))
mean(rowCounts(df2))
data_modify <- df2[rowCounts(df2) <= 2.266886]
dim(data_modify)
boxplot(Matrix::rowMeans(data_modify), horizontal=T)
# 아IBCF 알고리즘으로는 장르기반 별로?
eval_sets <- evaluationScheme(data = data_modify,
method = "cross-validation",
train = 0.7,
k = 10,
goodRating = 3,
given = 10)
n_recommendations = c(1,5,seq(10,100,10))
# Training dataset modeling
model1 <- Recommender(data = getData(eval_sets, "train"),
method = "IBCF",
parameter = NULL)
model1
# Prediction
pred_eval <- predict(model1,
newdata = getData(eval_sets, "known"),
n = 10, type = "ratings")
pred_eval
# 데이터 조정 후 재학습
table(rowCounts(df2))
mean(rowCounts(df2))
data_modify <- df2[rowCounts(df2) <= 2.266886]
dim(data_modify)
boxplot(Matrix::rowMeans(data_modify), horizontal=T)
eval_sets <- evaluationScheme(data = data_modify,
method = "cross-validation",
train = 0.7,
k = 10,
#goodRating = 3,
given = 10)
eval_sets <- evaluationScheme(data = data_modify,
method = "cross-validation",
train = 0.7,
k = 10,
#goodRating = 3,
given = 5)
#goodRating = 3,
#given = 10)
eval_sets <- evaluationScheme(data = data_modify,
method = "cross-validation",
train = 0.7,
k = 10,
#goodRating = 3,
#given = 10
)
eval_sets <- evaluationScheme(data = data_modify,
method = "cross-validation",
train = 0.7,
k = 10,
#goodRating = 3,
given = 3)
dim(data_modify)
eval_sets <- evaluationScheme(data = data_modify,
method = "cross-validation",
train = 0.7,
k = 3,
#goodRating = 3,
given = 3)
eval_sets <- evaluationScheme(data = data_modify,
method = "cross-validation",
train = 0.7,
k = 3,
#goodRating = 3,
given = 2)
eval_sets <- evaluationScheme(data = data_modify,
method = "cross-validation",
train = 0.7,
k = 3,
#goodRating = 3,
given = 1)
n_recommendations = c(1,5,seq(10,100,10))
# Training dataset modeling
model1 <- Recommender(data = getData(eval_sets, "train"),
method = "IBCF",
parameter = NULL)
model1
# Prediction
pred_eval <- predict(model1,
newdata = getData(eval_sets, "known"),
n = 10, type = "ratings")
pred_eval
# Calculate accuracy
accuracy_model1 <- calcPredictionAccuracy(x=pred_eval,
data=getData(eval_sets, "unknown"),
byUser=T)
head(accuracy_model1, 10)
colMeans(accuracy_model1)
# 유사도
similarity_mat <- similarity(model1[1:4, ], method = "cosine", which = "users")
set.seed(2021)
index <- sample(1:nrow(df), size = nrow(df)*0.7)
train <- df[index, ]
test  <- df[-index,]
model1 <- Recommender(train, method = "UBCF")
model1
# 유사도
similarity_mat <- similarity(model1[1:4, ], method = "cosine", which = "users")
# 유사도
similarity_mat <- similarity(train[1:4, ], method = "cosine", which = "users")
as.matrix(similarity_mat)
image(as.matrix(similarity_mat), main = "user's similiarity")
train[1:4, ]
train
View(train)
# 유사도
similarity_mat <- similarity(train, method = "cosine", which = "users")
as.matrix(similarity_mat)
image(as.matrix(similarity_mat), main = "user's similiarity")
# 유사도
similarity_mat <- similarity(train[1:10,], method = "cosine", which = "users")
as.matrix(similarity_mat)
image(as.matrix(similarity_mat), main = "user's similiarity")
# 관람수
movie_views <- colCounts(train) # Count views for each movie
#names(movie_views)
table_views <- data.frame(movie = names(movie_views),
views = movie_views) # create dataframe of views
table_views <- table_views[order(table_views$views,
decreasing = TRUE), ] # sort by number of views
image(train[1:30,1:30], axes=FALSE, main = "10 x 10 heatmap")
movie_ratings <- train[rowCounts(train) > 50, colCounts(train) > 50]
movie_ratings
minimum_movies <- quantile(rowCounts(movie_ratings), 0.98)
minimum_users <- quantile(colCounts(movie_ratings), 0.98)
image(movie_ratings[rowCounts(movie_ratings) > minimum_movies,
colCounts(movie_ratings) > minimum_users],
main = "Heatmap of the top users and movies")
qplot(average_ratings, fill=I("steelblue"), col=I("red")) +
ggtitle("A distribution of the average rating per user")
qplot(table(r$rating)s, fill=I("steelblue"), col=I("red")) +
ggtitle("A distribution of the average rating per user")
qplot(table(r$rating), fill=I("steelblue"), col=I("red")) +
ggtitle("A distribution of the average rating per user")
unique(r$rating)
table_rating <- table(r$rating)
table_rating
#   0.5     1   1.5     2   2.5     3   3.5     4   4.5     5
#  1370  2811  1791  7551  5550 20047 13136 26818  8551 13211
vector_ratings <- factor(r$rating)
qplot(vector_ratings) + ggtitle("Distribution of the ratings")
df_ratings_means<-r %>% group_by(movieId) %>% summarise(mean_rating = mean(rating), n=n()) %>% arrange(desc(n)) %>% head(10)
barplot(df_ratings_means$n ~ df_ratings_means$movieId)
ggplot()+geom_point(mapping=aes(x=mean_rating, y=n ), data=df_ratings_means, color = 'blue')
### 2-1.데이터수집
m <- read.csv('./data/movies.csv',header=T) # m = movies
r <- read.csv('./data/ratings.csv',header=T) # r = ratings
t <- read.csv('./data/tags.csv',header=T) # t = tags
### 2-2.데이터확인
df=m
#df=r
#df=t
glimpse(df)
summary(df)
# 결측치 확인
which(!complete.cases(df))
sum(is.na(df)); sum(!is.na(df))
# 이상치 확인
# 중복값 확인
sum(duplicated(df))
#결측치 요약 및 시각화
naniar::miss_case_summary(df) # case : 행 기준
naniar::miss_var_summary(df)  # variable : 변수 기준
naniar::gg_miss_var(df)
#VIM::aggr(df)
unique(r$rating)
# [1] 4.0 5.0 3.0 2.0 1.0 4.5 3.5 2.5 0.5 1.5
table_rating <- table(r$rating)
table_rating
#   0.5     1   1.5     2   2.5     3   3.5     4   4.5     5
#  1370  2811  1791  7551  5550 20047 13136 26818  8551 13211
vector_ratings <- factor(r$rating)
qplot(vector_ratings) + ggtitle("Distribution of the ratings")
df_ratings_means<-r %>% group_by(movieId) %>% summarise(mean_rating = mean(rating), n=n()) %>% arrange(desc(n)) %>% head(10)
barplot(df_ratings_means$n ~ df_ratings_means$movieId)
ggplot()+geom_point(mapping=aes(x=mean_rating, y=n ), data=df_ratings_means, color = 'blue')
r2 <- r %>% group_by(movieId) %>% summarise(mean_rating = mean(rating), .groups = 'drop')
barplot(r2$mean_rating~r2$movieId)
ggplot(data=r2,aes(x=r2$movieId,y=r2$mean_rating))+geom_point()
plot(r$movieId, r$mean_rating)
plot(r$movieId, r$mean_rating,type='l')
r2 <- as.data.frame(r2)
head(r2)
plot(r2$movieId, r2$mean_rating)
hist(r2[,2], main = colnames(r2)[1], breaks = 50, xlab = "평점")
df <- r %>% summarise(count_rating = n(userId))
count(r$userId[1])
barplot(table(r$userId))#다운샘플링 ?
barplot(table(r$userId))#다운샘플링 ?
#유저당 평점 갯수
df <- r %>% summarise(count_rating = n(userId))
t2 <- tolower(t$tag)
sort(t2, decreasing = T) #정렬
t3 <- table(t2)
palete <- brewer.pal(7,"Set3")
wordcloud(names(t3), freq=t3, scale=c(10,1), rot.per=0.1, min.freq=15,
random.order=F, random.color=T, colors=palete)
library(multilinguer)
library(KoNLP)
library(RColorBrewer)
library(wordcloud)
#movieId를 그룹으로 영화 평점 추출
df_ratings_means <- r %>% group_by(movieId) %>% summarise(mean_rating = mean(rating), n=n())
# 10명 이상 평가한 영화만 그래프에 표시
df_ratings_means_n_over10 <- subset(df_ratings_means,n >=10)
str(df_ratings_means_n_over10)
View(df_ratings_means_n_over10)
#막대그래프
barplot(df_ratings_means_n_over10$mean_rating~df_ratings_means_n_over10$movieId)
#산점도 그래프
ggplot(data=df_ratings_means_n_over10,aes(x=df_ratings_means_n_over10$movieId,y=df_ratings_means_n_over10$mean_rating))+geom_point()
#산점도 그래프
plot(df_ratings_means_n_over10$movieId, df_ratings_means_n_over10$mean_rating)
#꺾은선 그래프
plot(df_ratings_means_n_over10$movieId,df_ratings_means_n_over10$mean_rating,type='l')
head(m)
### 2-1.데이터수집
m <- read.csv('./data/movies.csv',header=T) # m = movies
head(m)
m <- m[order(m$movieId),]
m$idx <- 1:nrow(m)
head(m)
m = m[,-c(1,3)]
head(m)
mg <- merge(m, g, key='idx', all.y=T)
head(g)
# movies에 있는 장르분리 및 장르df생성
g <- data.table()
n <- nrow(m)
for (i in 1:n){
#print(i)
name_index <- as.character(m[i, 1])
item_index <- as.character(m[i, 3])
item_index_split_temp <- data.frame(strsplit(item_index, split = '\\|'))
m_temp <- data.frame(cbind(name_index, item_index_split_temp))
names(m_temp) <- c("movieId", "genres")
g <- rbind(g, m_temp)
}
### 2-1.데이터수집
m <- read.csv('./data/movies.csv',header=T) # m = movies
#무비id 오름차순 정렬 후 새 인덱스 부여
m <- m[order(m$movieId),]
m$idx <- 1:nrow(m)
# movies에 있는 장르분리 및 장르df생성
g <- data.table()
n <- nrow(m)
for (i in 1:n){
#print(i)
name_index <- as.character(m[i, 1])
item_index <- as.character(m[i, 3])
item_index_split_temp <- data.frame(strsplit(item_index, split = '\\|'))
m_temp <- data.frame(cbind(name_index, item_index_split_temp))
names(m_temp) <- c("movieId", "genres")
g <- rbind(g, m_temp)
}
rm(name_index, item_index, item_index_split_temp, m_temp) # delete temp dataset
g$movieId <- as.integer(g$movieId)
head(m)
unique(g$genres)
#(no genres listed) -> NA 결측치 처리
g$genres<- gsub("\\(no genres listed\\)", NA, g$genres)
barplot(table(g$genres))
g <- as.data.frame(g)
write.csv(g, "./data/genres.csv",row.names = F)
head(m)
#장르 기반 - mg 데이터셋 구축
m$value = 1
m = m[,-c(1,3)]
m2=m
mg <- merge(m2, g, key='idx', all.y=T)
head(m2)
head(g)
sum(duplicated(m2))
View(mg)
mg <- merge(m2, g, key='idx', all.y=T)
# Chunk 1: setup
knitr::opts_chunk$set(echo=F, fig.align = "center", message=F, warning=F, fig.height = 8, cache=T, dpi = 300, dev = "png")
# Chunk 2
#전처리에 필요한 라이브러리
library(data.table)
library(tidyverse)
library(dplyr)
library(naniar)
library(VIM)
library(DT)
library(ggplot2)
#시각화에 필요한 라이브러리
library(multilinguer)
library(RColorBrewer)
library(wordcloud)
#추천알고리즘 라이브러리
library(recommenderlab)
# Chunk 3
### 2-1.데이터수집
m <- read.csv('./data/movies.csv',header=T) # m = movies
r <- read.csv('./data/ratings.csv',header=T) # r = ratings
t <- read.csv('./data/tags.csv',header=T) # t = tags
### 2-2.데이터확인
df=m
#df=r
#df=t
glimpse(df)
summary(df)
# 결측치 확인
which(!complete.cases(df))
sum(is.na(df)); sum(!is.na(df))
# 이상치 확인
# 중복값 확인
sum(duplicated(df))
#결측치 요약 및 시각화
naniar::miss_case_summary(df) # case : 행 기준
naniar::miss_var_summary(df)  # variable : 변수 기준
naniar::gg_miss_var(df)
#VIM::aggr(df)
# Chunk 4
unique(r$rating)
# [1] 4.0 5.0 3.0 2.0 1.0 4.5 3.5 2.5 0.5 1.5
# Chunk 5
table_rating <- table(r$rating)
table_rating
#   0.5     1   1.5     2   2.5     3   3.5     4   4.5     5
#  1370  2811  1791  7551  5550 20047 13136 26818  8551 13211
# Chunk 6
vector_ratings <- factor(r$rating)
qplot(vector_ratings) + ggtitle("Distribution of the ratings")
# Chunk 7
df_ratings_means<-r %>% group_by(movieId) %>% summarise(mean_rating = mean(rating), n=n()) %>% arrange(desc(n)) %>% head(10)
barplot(df_ratings_means$n ~ df_ratings_means$movieId)
# Chunk 8
ggplot()+geom_point(mapping=aes(x=mean_rating, y=n), data=df_ratings_means, color = 'blue')
# Chunk 9
#영화별 평점
# r2 <- r %>% group_by(movieId) %>% summarise(mean_rating = mean(rating), .groups = 'drop')
# barplot(r2$mean_rating~r2$movieId)
# ggplot(data=r2,aes(x=r2$movieId,y=r2$mean_rating))+geom_point()
# plot(r$movieId, r$mean_rating)
# plot(r$movieId, r$mean_rating,type='l')
#
# r2 <- as.data.frame(r2)
# head(r2)
# plot(r2$movieId, r2$mean_rating)
# hist(r2[,2], main = colnames(r2)[1], breaks = 50, xlab = "평점")
# Chunk 10
t2 <- tolower(t$tag)
sort(t2, decreasing = T) #정렬
t3 <- table(t2)
palete <- brewer.pal(7,"Set3")
wordcloud(names(t3), freq=t3, scale=c(10,1), rot.per=0.1, min.freq=15,
random.order=F, random.color=T, colors=palete)
# Chunk 11
#movieId를 그룹으로 영화 평점 추출
df_ratings_means <- r %>% group_by(movieId) %>% summarise(mean_rating = mean(rating), n=n())
# 10명 이상 평가한 영화만 그래프에 표시
df_ratings_means_n_over10 <- subset(df_ratings_means,n >=10)
str(df_ratings_means_n_over10)
#View(df_ratings_means_n_over10)
#막대그래프
barplot(df_ratings_means_n_over10$mean_rating~df_ratings_means_n_over10$movieId)
#산점도 그래프
ggplot(data=df_ratings_means_n_over10,aes(x=df_ratings_means_n_over10$movieId,y=df_ratings_means_n_over10$mean_rating))+geom_point()
#산점도 그래프
plot(df_ratings_means_n_over10$movieId, df_ratings_means_n_over10$mean_rating)
#꺾은선 그래프
plot(df_ratings_means_n_over10$movieId,df_ratings_means_n_over10$mean_rating,type='l')
# Chunk 12
#무비id 오름차순 정렬 후 새 인덱스 부여
m <- m[order(m$movieId),]
m$idx <- 1:nrow(m)
#movies - rating 병합
mr <- merge(m, r, key='movieId', all.y=T)
mr <- mr[,-c(1,7)]
mr <- mr[,-c(2,3)]
sum(duplicated(mr)) #[1] 3
which(duplicated(mr)|duplicated(mr,fromLast=T))
mr[which(duplicated(mr)|duplicated(mr,fromLast=T)),]
mr <- mr[-which(duplicated(mr)|duplicated(mr,fromLast=T)),]
mr <- mr[-c(80209,88669),]
write.csv(mr, "./data/mr.csv",row.names = F)
# Chunk 13
# movies에 있는 장르분리 및 장르df생성
g <- data.table()
n <- nrow(m)
for (i in 1:n){
#print(i)
name_index <- as.character(m[i, 1])
item_index <- as.character(m[i, 3])
item_index_split_temp <- data.frame(strsplit(item_index, split = '\\|'))
m_temp <- data.frame(cbind(name_index, item_index_split_temp))
names(m_temp) <- c("movieId", "genres")
g <- rbind(g, m_temp)
}
rm(name_index, item_index, item_index_split_temp, m_temp) # delete temp dataset
glimpse(g)
summary(g)
g$movieId <- as.integer(g$movieId)
unique(g$genres)
#(no genres listed) -> NA 결측치 처리
g$genres<- gsub("\\(no genres listed\\)", NA, g$genres)
barplot(table(g$genres))
g <- as.data.frame(g)
write.csv(g, "./data/genres.csv",row.names = F)
#장르 기반 - mg 데이터셋 구축
m$value = 1
m2 = m[,-c(1,3)]
mg <- merge(m2, g, key='idx', all.y=T)
head(m2)
head(g)
names(g) <- c("idx","genres")
unique(g$genres)
#(no genres listed) -> NA 결측치 처리
g$genres<- gsub("\\(no genres listed\\)", NA, g$genres)
barplot(table(g$genres))
g <- as.data.frame(g)
write.csv(g, "./data/genres.csv",row.names = F)
m$value = 1
m2 = m[,-c(1,3)]
mg <- merge(m2, g, key='idx', all.y=T)
head(mg)
head(m2)
head(g)
mg <- merge(m2, g, key='idx', all.y=T)
head(mg)
?Recommender
??Recommender
recommenderRegistry$get_entries()
# Chunk 1: setup
knitr::opts_chunk$set(echo=T, fig.align = "center", message=F, warning=F, fig.height = 8, cache=T, dpi = 300, dev = "png")
# Chunk 2
library(data.table)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(recommenderlab)
#help(package="recommenderlab")
r <- read.csv("./data/ratings.csv", header=T)
mr <- read.csv("./data/mr.csv", header=T)
final_mr <- spread(mr, key = "title", value = "rating", fill = NA)
final_mr <- final_mr[,-1]
# Chunk 3
knitr::kable(head(mr))
#knitr::kable(head(mr[order(mr$userId),]))
#knitr::kable(head(mr[order(mr$rating),]))
knitr::kable(table(r$rating))
df <- as(final_mr, 'matrix')
df <- as(df, 'realRatingMatrix')
# Chunk 4
set.seed(2021)
index <- sample(1:nrow(df), size = nrow(df)*0.7)
train <- df[index, ]
test  <- df[-index,]
model1 <- Recommender(train, method = "UBCF")
model1
pre <- predict(model1, newdata=test[1], n=10) #test 1 ~ 183
# as(pre, "list")
# just check
pre_list <- sapply(pre@items, function(x) {colnames(train)[x]})
table(unlist(lapply(pre_list, length)))
knitr::kable(pre_list[])
# Chunk 5
# 유사도
similarity_mat <- similarity(train[1:10,], method = "cosine", which = "users")
as.matrix(similarity_mat)
image(as.matrix(similarity_mat), main = "user's similiarity")
# 히트맵
image(train[1:30,1:30], axes=FALSE, main = "10 x 10 heatmap")
# top
movie_ratings <- train[rowCounts(train) > 50, colCounts(train) > 50]
movie_ratings
minimum_movies <- quantile(rowCounts(movie_ratings), 0.98)
minimum_users <- quantile(colCounts(movie_ratings), 0.98)
image(movie_ratings[rowCounts(movie_ratings) > minimum_movies,
colCounts(movie_ratings) > minimum_users],
main = "Heatmap of the top users and movies")
## 데이터..
# qplot(table(r$rating), fill=I("steelblue"), col=I("red")) +
#   ggtitle("A distribution of the average rating per user")
# heatmap of normalized value
# image(normalized_ratings[rowCounts(normalized_ratings) > minimum_movies,
#       colCounts(normalized_ratings) > minimum_users],
#       main = "Normailized ratings of the top users")
# 데이터 조정 후 재학습
table(rowCounts(df))
mean(rowCounts(df))
data_modify <- df[rowCounts(df) <= 165.2918]
dim(data_modify)
boxplot(Matrix::rowMeans(data_modify), horizontal=T)
??Recommender
