library(XML)
library(stringr)
library(rvest)
library(tidytext)
library(extrafont)
loadfonts()
library(doParallel)
library(dplyr)
genre<-"Action"
genre_words <- genres_tags %>%
filter(genres == genre) %>%
unnest() %>%
mutate(tag = str_to_lower(tag, "en")) %>%
anti_join(tibble(tag=c(tolower(genre)))) %>%
count(tag)
wordcloud(genre_words$tag, genre_words$n, max.words = 50, colors=brewer.pal(8, "Dark2"))
wordcloud(genre_words$tag, genre_words$n, max.words = 50, colors=brewer.pal(8, "Dark2"))
# plot wordcloud per genre
genre<-"Comedy"
genre_words <- genres_tags %>%
filter(genres == genre) %>%
unnest() %>%
mutate(tag = str_to_lower(tag, "en")) %>%
anti_join(tibble(tag=c(tolower(genre)))) %>%
count(tag)
wordcloud(genre_words$tag, genre_words$n, max.words = 50, colors=brewer.pal(8, "Dark2"))
# plot wordcloud per genre
genre<-"Drama"
genre_words <- genres_tags %>%
filter(genres == genre) %>%
unnest() %>%
mutate(tag = str_to_lower(tag, "en")) %>%
anti_join(tibble(tag=c(tolower(genre)))) %>%
count(tag)
wordcloud(genre_words$tag, genre_words$n, max.words = 50, colors=brewer.pal(8, "Dark2"))
genre_words <- genres_tags %>%
filter(genres == genre) %>%
unnest(cols=c(genre)) %>%
mutate(tag = str_to_lower(tag, "en")) %>%
anti_join(tibble(tag=c(tolower(genre)))) %>%
count(tag)
wordcloud(genre_words$tag, genre_words$n, max.words = 50, colors=brewer.pal(8, "Dark2"))
avg_rating <- ratings_df %>%
inner_join(movies_df, by = "movieId") %>%
na.omit() %>%
select(movieId, title, rating, year) %>%
group_by(movieId, title, year) %>%
summarise(count = n(), mean = mean(rating), min = min(rating), max = max(rating)) %>%
ungroup() %>%
arrange(desc(mean))
weighted_rating <- function(R, v, m, C) {
return (v/(v+m))*R + (m/(v+m))*C
}
# R = average for the movie (mean) = (Rating)
# v = number of votes for the movie = (votes)
# m = minimum votes required to be listed in the Top 250
# C = the mean vote across the whole report
avg_rating <- avg_rating %>%
mutate(wr = weighted_rating(mean, count, 500, mean(mean))) %>%
arrange(desc(wr))
avg_rating
avg_rating %>%
mutate(decade = year  %/% 10 * 10) %>%
arrange(year, desc(wr)) %>%
group_by(decade) %>%
summarise(title = first(title), wr = first(wr), mean = first(mean), count = first(count)) %>%
DT::datatable() %>%
DT::formatRound("count", digits = 0, interval = 3)
genres_rating <- movies_df %>%
na.omit() %>%
select(movieId, year, genres) %>%
inner_join(ratings_df, by = "movieId") %>%
select(-timestamp, -userId) %>%
mutate(decade = year  %/% 10 * 10) %>%
separate_rows(genres, sep = "\\|") %>%
group_by(year, genres) %>%
summarise(count = n(), avg_rating = mean(rating)) %>%
ungroup() %>%
mutate(wr = weighted_rating(mean, count, 500, mean(mean))) %>%
arrange(year)
genres_rating %>%
filter(genres %in% c("Action", "Romance", "Sci-Fi", "Western")) %>%
ggplot(aes(x = year, y = wr)) +
geom_line(aes(group=genres, color=genres)) +
geom_smooth(aes(group=genres, color=genres)) +
facet_wrap(~genres)
library(dplyr)
library(data.table)
library(reshape2)
#df <- read.csv("./tmdb_5000_movies.csv", header=T)
df <- read.csv("./data/movie_metadata.csv", header=T)
str(df)
dim(df) #[1] 5043   28
# duplicate rows
sum(duplicated(df))
# delete duplicate rows
df <- df[!duplicated(df), ]
library(stringr)
df$movie_title <- gsub("혻", "", as.character(factor(df$movie_title)))
str_trim(df$movie_title, side = "right")
head(df$genres)
#무비렌즈 100,000 ratings
#943유저*1664영화
#1997.9.19 ~ 1998.4.22
m <- read.csv('./data/MovieLense.csv', stringsAsFactors=F)
str(m)
nrow(m)
ncol(m)
head(m)
#원소 총 갯수
nrow(m) * ncol(m)
#NA
sum(is.na(m))
sum(!is.na(m))
#영화별 평균 평점 히스토그램
hist(colMeans(m, na.rm = T))
hist(colMeans(m, na.rm = T), breaks = 50)
#영화별 평균 평점 히스토그램
hist(colMeans(m, na.rm = T))
#영화별 평균 평점 히스토그램
hist(colMeans(m, na.rm = T), breaks = 50)
#개인당 몇 개의 영화에 대하여 평점을 매겼을까?
hist(apply(m, 1, function(x) sum(!is.na(x))), breaks = 50)
colMeans(m, na.rm=T)
apply(m, 2, mean, na.rm=T)
apply(m, 2, median, na.rm=T)
#영화별 사용자 평점 히스토그램
hist(m[,1], main = colnames(m)[1])
hist(m[,2], main = colnames(m)[2])
hist(m[,3], main = colnames(m)[3])
hist(m[,4], main = colnames(m)[4])
hist(m[,5], main = colnames(m)[5])
#데이터 탐색
View(m)
hist(m[,1664], main = colnames(m)[1664])
hist(m[,1554], main = colnames(m)[1554])
hist(m[,5], main = colnames(m)[5])
str(m)
colnames(m)[5]
m[,5]
m[,4]
m[,1664]
m[,999]
hist(m[,999], main = colnames(m)[999])
#개인당 몇 개의 영화에 대하여 평점을 매겼을까?
hist(apply(m, 1, function(x) sum(!is.na(x))), breaks = 50)
title("개인당 평점을 매긴 영화갯수수")
#개인당 몇 개의 영화에 대하여 평점을 매겼을까?
hist(apply(m, 1, function(x) sum(!is.na(x))), breaks = 50,
main="개인당 평점을 매긴 영화갯수")
library(recommenderlab)
m <- read.csv('./data/MovieLense.csv', stringsAsFactors=F)
#sparse(NA가 많은)한 데이터를 R에서 잘 다룰 수 있도록 데이터 타입 변경
m <- as(m, 'matrix')
m <- as(m, 'realRatingMatrix')
colMeans(m)
m
#평점 추출하기
hist(getRatings(m))
#3,4,5점에 편중되어 있는 것 같다.
#오른쪽으로 치우쳐진
summary(getRatings(m))
getRatings(m)
#평점 추출하기(na는 사라진다) - 모든 사용자의 평점
hist(getRatings(m), main="모든 사용자의 평점 빈도")
#3,4,5점에 편중되어 있는 것 같다.
#오른쪽으로 치우쳐진
summary(getRatings(m))
#표준화, 평균빼기를 통해 상관계수, 코사인 유사도 정확도 업
normalize(m, method="center")
#각 사용자의 평점을 각 사용자별로 평균을 빼준 뒤 (mean centering) 평점 알아보기
hist(getRatings(normalize(m, method='center')))
#각 사용자의 평점을 각 사용자별로 평균을 빼준 뒤 (mean centering) 평점 알아보기
hist(getRatings(normalize(m, method='center')), main="평점-평균")
summary(getRatings(normalize(m, method='center')))
#각 사용자의 평점을 각 사용자별로 표준화 한 뒤 평점 알아보기
hist(getRatings(normalize(m, method = 'Z-score')), main="표준화")
summary(getRatings(normalize(m, method = 'Z-score')))
#recommenderlab에서 기본적으로 사용가능한 추천 알고리즘 확인
recommenderRegistry$get_entries()
#데이터가 평점 등 실수(real) 데이터 일 경우
#recommenderlab에서 기본적으로 사용가능한 추천 알고리즘 확인
recommenderRegistry$get_entries(dataType = 'realRatingMatrix')
#평균 평점이 높은 영화 순(인기순)으로 추천하기 (학습 단계)
rec <- Recommender(m, method = 'POPULAR')
rec
#1번(첫번째) 사람에 대해 평점 예측(predict)(추천 단계)
who <- 1
predict(rec, m[who, ], type = 'ratings')
as(predict(rec, m[who, ], type = 'ratings'), 'list')
as(predict(rec, m[who, ], type = 'ratings'), 'list')
#1번(첫번째) 사람에 대해 평점을 예측(predict)하되,
#평점이 높은 영화 5개만 추천(추천 단계)
as(predict(rec, m[who, ], type = 'topNList', n = 5))
#1번(첫번째) 사람에 대해 평점을 예측(predict)하되,
#평점이 높은 영화 5개만 추천(추천 단계)
predict(rec, m[who, ], type = 'topNList', n = 5)
as(predict(rec, m[who, ], type = 'topNList', n = 5), 'list')
as(predict(rec, m[2, ], type = 'topNList', n=5), 'list')
as(predict(rec, m[1664, ], type = 'topNList', n=5), 'list')
as(predict(rec, m[943, ], type = 'topNList', n=5), 'list')
##2
#평점 데이터를 사용자별로 표준화 한 뒤,
#평균 평점이 높은 영화 순(인기순)으로 추천(학습 단계)
rec <- Recommender(m, method = 'POPULAR', param = list(normalize = 'Z-score'))
rec
#1번(첫번째) 사람에 대해 평점을 예측(predict)하되,
#평점이 높은 영화 5개만 추천(추천 단계)
as(predict(rec, m[who, ], type = 'topNList', n = 5), 'list')
as(predict(rec, m[2, ], type = 'topNList', n=5), 'list')
as(predict(rec, m[943, ], type = 'topNList', n=5), 'list')
#User-Based Collaborative Filtering(UBCF)에서
#조정할 수 있는 파라미터
recommenderRegistry$get_entries(method = 'UBCF')
recommenderRegistry
recommenderRegistry$get_entry(method='UBCF')
recommenderRegistry$get_entries(method='UBCF')
recommenderRegistry$get_entry_names(method='UBCF')
recommenderRegistry$get_entry_names()
recommenderRegistry$get_entries(method="UBCF_realRatingMatrix")
recommenderRegistry$get_entries(method="UBCF_realRatingMatrix")
UBCF_realRatingMatrix
recommenderRegistry$get_entry()
#User-Based Collaborative Filtering(UBCF)에서
#조정할 수 있는 파라미터
recommenderRegistry$get_entry(method = 'UBCF')
#User-Based Collaborative Filtering(UBCF)에서
#조정할 수 있는 파라미터
recommenderRegistry$get_entry('UBCF_realRatingMatrix')
#User-Based Collaborative Filtering(UBCF)에서
#조정할 수 있는 파라미터
recommenderRegistry$get_entry(method='UBCF_realRatingMatrix')
#User-Based Collaborative Filtering(UBCF)에서
#조정할 수 있는 파라미터
recommenderRegistry$get_entry(method='UBC')
#데이터가 평점 등 실수(real) 데이터 일 경우
#recommenderlab에서 기본적으로 사용가능한 추천 알고리즘 확인
recommenderRegistry$get_entries(dataType = 'realRatingMatrix')
#데이터가 평점 등 실수(real) 데이터 일 경우
#recommenderlab에서 기본적으로 사용가능한 추천 알고리즘 확인
recommenderRegistry$get_entry(dataType = 'realRatingMatrix')
#피어슨 상관계수를 이용하여 추천
rec <- Recommender(m, method='UBCF', param=list(method='pearson'))
who <- 1
as(predict(rec, m[who, ], type = 'ratings'), 'list')
as(predict(rec, m[who, ], type = 'topNList', n = 5), 'list')
as(predict(rec, m[who, ], type = 'ratings'), 'list')
#코사인 유사도를 이용하여 추천해보기
rec <- Recommender(m, method='UBCF', param=list(method='cosine'))
as(predict(rec, m[who, ], type='topNList', n=5), 'list')
as(predict(rec, m[who, ], type = 'topNList', n=5), 'list')
#추천 시 특정 사용자와 인접한 이웃의 수를 50으로 설정하여 추천
rec <- Recommender(m, method='UBCF', param=list(method='cosine', nn=50))
as(predict(rec, m[who, ], type='topNList', n=5), 'list')
#Item Based Collaborative Filtering(IBCF)에서
#조정할 수 있는 파라미터 알아보기
recommenderRegistry$get_entries(method = 'IBCF')
#Item Based Collaborative Filtering(IBCF)에서
#조정할 수 있는 파라미터 알아보기
recommenderRegistry$get_entry(method = 'IBCF')
m <- as(m, 'matrix')
m <- as(m, 'realRatingMatrix')
#Item Based Collaborative Filtering(IBCF)에서
#조정할 수 있는 파라미터 알아보기
recommenderRegistry$get_entry(method = 'IBCF')
#피어슨 상관계수를 이용하여 추천
rec <- Recommender(m, method = "IBCF", param=list(method = 'pearson'))
who <- 1
as(predict(rec, m[who,], type = 'topNList', n=5), 'list')
as(predict(rec, m[who,], type = 'ratings', n=5), 'list')
#피어슨 상관계수를 이용하여 추천
rec <- Recommender(m, method = "IBCF", param=list(method = 'pearson'))
who <- 1
as(predict(rec, m[who,], type = 'ratings', n=5), 'list')
#유사도를 행별로 normalize(행별로 유사도 합이 1이 되도록 재조정)
#한 후 피어슨 상관계수를 이용하여 추천
rec <- Recommender(m, method = "IBCF", param=list(method = 'pearson', normalize_sim_matrix = T))
as(predict(rec, m[who,], type = 'ratings', n=5), 'list')
as(predict(rec, m[who,], type = 'topNList', n=5), 'list')
#파라미터 조정 method='cosine', k=10
rec <- Recommender(m, method = "IBCF", param=list(method = 'cosine', normalize_sim_matrix = T), k=5)
#파라미터 조정 method='cosine', k=10
rec <- Recommender(m, method = "IBCF", param=list(method = 'cosine', normalize_sim_matrix = T), nn=5)
#파라미터 조정 method='cosine', k=10
rec <- Recommender(m, method = "IBCF", param=list(method = 'cosine', normalize_sim_matrix = T, k=5))
as(predict(rec, m[who,], type = 'topNList', n=5), 'list')
m
m <- read.csv('./data/MovieLense.csv', stringsAsFactors=F)
m
head(m)
View(m)
#차원 축소를 이용한 영화 추천
#SVD 에서 조정할 수 있는 파라미터
recommenderRegistry$get_entries(method = 'SVD')
#차원 축소를 이용한 영화 추천
#SVD 에서 조정할 수 있는 파라미터
recommenderRegistry$get_entry(method = 'SVD')
m <- as(m, 'matrix')
m <- as(m, 'realRatingMatrix')
#차원 축소를 이용한 영화 추천
#SVD 에서 조정할 수 있는 파라미터
recommenderRegistry$get_entry(method = 'SVD')
#10개의 차원으로 축소한 뒤 추천해보기
rec <- Recommender(m, method = "SVD", param=list(k = 30))
who <- 1
predict(rec, m[who,])
predict(rec, m[who,], type='topNList', n=5, 'list')
as(predict(rec, m[who,], type='topNList', n=5), 'list')
rec <- Recommender(m, method = "SVD", param=list(k = 20, normalize='Z-score'))
as(predict(rec, m[c(1,3),], type = 'topNList', n = 5), 'list')
predict(rec, m[c(1,3),], type = 'topNList', n = 5)
rec <- Recommender(m, method = "SVD", param=list(k = 20))
as(predict(rec, m[c(1,3),], type = 'topNList', n = 5), 'list')
#추천 시스템에서의 모형 선택 (평점 기준)
#모형 평가를 위해서 Traing Set과 Test Set 분할하기
scheme <- evaluationScheme(m, method="split",
train = .8, k = 1, given = 15)
View(scheme)
m <- read.csv('./data/MovieLense.csv', stringsAsFactors=F)
#추천 시스템에서의 모형 선택 (평점 기준)
#모형 평가를 위해서 Traing Set과 Test Set 분할하기
scheme <- evaluationScheme(m, method="split",
train = .8, k = 1, given = 15)
m <- as(m, 'matrix')
m <- as(m, 'realRatingMatrix')
#추천 시스템에서의 모형 선택 (평점 기준)
#모형 평가를 위해서 Traing Set과 Test Set 분할하기
scheme <- evaluationScheme(m, method="split",
train = .8, k = 1, given = 15)
scheme@runsTrain
algorithms <- list(
"random" = list(name="RANDOM"),
"popular" = list(name="POPULAR"),
"popularZ" = list(name="POPULAR", param=list(normalize = "Z-score")),
"userN10C" = list(name="UBCF", param=list(normalize = NULL, nn = 10, method = 'cosine')),
"userN10P" = list(name="UBCF", param=list(normalize = NULL, nn = 10, method = 'pearson')),
"userN50C" = list(name="UBCF", param=list(normalize = NULL, nn = 50, method = 'cosine')),
"userN50P" = list(name="UBCF", param=list(normalize = NULL, nn = 50, method = 'pearson')),
"userC50C" = list(name="UBCF", param=list(normalize = 'center', nn = 50, method = 'cosine')),
"userC50P" = list(name="UBCF", param=list(normalize = 'center', nn = 50, method = 'pearson')),
"userZ50C" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 50, method = 'cosine')),
"userZ50P" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 50, method = 'pearson')),
"userZ100C" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 100, method = 'cosine')),
"userZ100P" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 100, method = 'pearson')),
"userZ500C" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 500, method = 'cosine')),
"userZ500P" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 500, method = 'pearson'))
)
#Training Set으로 각 알고리즘에 대해서 학습 후
#Test Set을 이용하여 정확도 평가하기
results <- evaluate(scheme, algorithms, type='ratings')
#각 모형에 대한 정확도 확인하기
names(results)
getConfusionMatrix(results[['random']])
getConfusionMatrix(results[['popular']])
for (i in names(results))
{
print(i)
print(getConfusionMatrix(results[[i]]))
}
#각 모형에 대한 정확도를 그림으로 나타내기
plot(results)
#User Based CF외에 Item Based CF와 SVD를 추가하여 모형 평가하기
algorithms <- list(
"random" = list(name="RANDOM"),
"popular" = list(name="POPULAR"),
"popularZ" = list(name="POPULAR", param=list(normalize = "Z-score")),
"userN10C" = list(name="UBCF", param=list(normalize = NULL, nn = 10, method = 'cosine')),
"userZ500C" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 500, method = 'cosine')),
"itemZ100PF" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'pearson', normalize_sim_matrix = F)),
"itemZ100PT" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'pearson', normalize_sim_matrix = T)),
"itemZ100CF" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'cosine', normalize_sim_matrix = F)),
"itemZ100CT" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'cosine', normalize_sim_matrix = T)),
"itemZ500PT" = list(name="IBCF", param=list(normalize = 'Z-score', k = 500, method = 'pearson', normalize_sim_matrix = T)),
"itemZ500CT" = list(name="IBCF", param=list(normalize = 'Z-score', k = 500, method = 'cosine', normalize_sim_matrix = T)),
'SVDZ10PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 10)),
'SVDZ50PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 50)),
'SVDZ100PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 100)),
)
results <- evaluate(scheme, algorithms, type='ratings')
for (i in names(results)){
print(i)
print(getConfusionMatrix(results[[i]]))
}
plot(results)
##추천 시스템에서의 모형 선택 (추천목록기준)
#모형 평가를 위해서 Traing Set과 Test Set 분할하기:
#단, 3점 이상일 경우 재미있게 봤다고 가정
set.seed(12345)
scheme <- evaluationScheme(m, method="split",
train = .8, k = 1, given = 15, goodRating = 3)
#평가할 알고리즘 설정하기
algorithms <- list(
"random" = list(name="RANDOM"),
"popular" = list(name="POPULAR"),
"popularZ" = list(name="POPULAR", param=list(normalize = "Z-score")),
"userN10C" = list(name="UBCF", param=list(normalize = NULL, nn = 10, method = 'cosine')),
"userN10P" = list(name="UBCF", param=list(normalize = NULL, nn = 10, method = 'pearson')),
"userN50C" = list(name="UBCF", param=list(normalize = NULL, nn = 50, method = 'cosine')),
"userN50P" = list(name="UBCF", param=list(normalize = NULL, nn = 50, method = 'pearson')),
"userC50C" = list(name="UBCF", param=list(normalize = 'center', nn = 50, method = 'cosine')),
"userC50P" = list(name="UBCF", param=list(normalize = 'center', nn = 50, method = 'pearson')),
"userZ50C" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 50, method = 'cosine')),
"userZ50P" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 50, method = 'pearson')),
"userZ100C" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 100, method = 'cosine')),
"userZ100P" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 100, method = 'pearson')),
"userZ500C" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 500, method = 'cosine')),
"userZ500P" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 500, method = 'pearson'))
)
#Training Set으로 각 알고리즘에 대해서 학습 후 Test Set을 이용하여 정확도 평가
results <- evaluate(scheme, algorithms, type='topNList', n=c(1, 3, 5, 10, 15, 20))
#Training Set으로 각 알고리즘에 대해서 학습 후 Test Set을 이용하여 정확도 평가
results <- evaluate(scheme, algorithms, type='topNList', n=c(1, 3, 5, 10, 15, 20))
#정확도 결과 그래프로 나타내기
plot(results, annotate = 1, legend="topleft")
?evaluate
?evaluate()
#데이터 불러오기
m <- read.csv('./data/MovieNaver.csv', fileEncoding='UTF-8', stringsAsFactors=F)
#데이터 탐색
dim(m)
colnames(m)
nrow(m)*ncol(m)
sum(is.na(m))
sum(!is.na(m))
hist(colMeans(m, na.rm = T))
hist(colMeans(m, na.rm = T), breaks = 50)
hist(colMeans(m, na.rm = T))
hist(colMeans(m, na.rm = T), breaks = 50)
hist(colMeans(m, na.rm = T))
hist(colMeans(m, na.rm = T), breaks = 50)
hist(apply(m, 1, function(x) sum(!is.na(x))), breaks = 50)
min(apply(m, 1, function(x) sum(!is.na(x))))
max(apply(m, 1, function(x) sum(!is.na(x))))
par(family = 'AppleGothic')
hist(m[,1], main = names(m)[1])
hist(m[,2], main = names(m)[2])
hist(m[,3], main = names(m)[3])
hist(m[,4], main = names(m)[4])
hist(m[,5], main = names(m)[5])
hist(apply(m, 1, function(x) sum(!is.na(x))), breaks = 50)
hist(apply(m, 1, function(x) sum(!is.na(x))),
breaks = 50, main="개인당 작성한 평점 갯수")
min(apply(m, 1, function(x) sum(!is.na(x))))
max(apply(m, 1, function(x) sum(!is.na(x))))
layout(mat=m)
layout(mat=2)
layout(mat=3)
hist(m[,1], main = names(m)[1])
hist(m[,2], main = names(m)[2])
par(font=1)
hist(m[,1], main = names(m)[1])
hist(m[,2], main = names(m)[2])
par(font=5)
hist(m[,1], main = names(m)[1])
hist(m[,2], main = names(m)[2])
par(mar=c(2,2))
hist(m[,1], main = names(m)[1])
hist(m[,2], main = names(m)[2])
m <- as(m, 'matrix')
m <- as(m, 'realRatingMatrix')
#평점을 기준으로 여러 모형들의 정확도 평가
scheme <- evaluationScheme(m, method="split",
train = .8, k = 1, given = 3)
algorithms <- list(
"random" = list(name="RANDOM"),
"popular" = list(name="POPULAR"),
"popularZ" = list(name="POPULAR", param=list(normalize = "Z-score")),
"userZ50C" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 50, method = 'cosine')),
"userZ50P" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 50, method = 'pearson')),
"itemZ100PF" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'pearson', normalize_sim_matrix = F)),
"itemZ100PT" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'pearson', normalize_sim_matrix = T)),
'SVDZ10PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 10)),
'SVDZ10CF' = list(name="SVD", param=list(normalize = 'Z-score', k = 50)),
'SVDZ50PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 100))
)
results <- evaluate(scheme, algorithms, type='ratings')
plot.new()
par(resetPar())
frame()
par(mfrow=c(1,1))
print(i)
for(i in names(results)){
print(i)
print(getConfusionMatrix(results[[i]]))
}
plot(results)
par(font=1)
plot(results)
##추천 TOP LIST를 기준으로 여러 모형들의 정확도 평가
scheme <- evaluationScheme(m, method="split",
train=.8, k=1, given=3, goodRating=6)
results <- evaluate(scheme, algorithms, type='topNList', n=c(1, 3, 5, 10, 15, 20))
irlba
library(irlba)
plot(results, annotate = 1, legend="topleft")
results <- evaluate(scheme, algorithms, type='topNList', n=c(1, 3, 5, 10, 15, 20))
plot(results, annotate = 1, legend="topleft")
#최종 알고리즘은 UBCF(데이터 사용자별 표준화(Z-score),
#인접한 이웃 50명, 유사도는 피어슨 상관계수)로 결정
rec <- Recommender(m, method = 'UBCF', param=list(normalize = 'Z-score', nn = 50, method = 'pearson'))
#5번째 사람에게 추천 영화 5개를 추천해봄
as(predict(rec, m[5,], type = 'topNList', n = 5), 'list')
as(m[5,], 'list')
rec <- Recommender(m, method = 'UBCF', param=list(normalize = 'Z-score', nn = 50, method = 'cosine'))
#5번째 사람에게 추천 영화 5개를 추천해봄
as(predict(rec, m[5,], type = 'topNList', n = 5), 'list')
as(m[5,], 'list')
#최종 알고리즘은 UBCF(데이터 사용자별 표준화(Z-score),
#인접한 이웃 50명, 유사도는 피어슨 상관계수)로 결정
rec <- Recommender(m, method = 'UBCF', param=list(normalize = 'Z-score', nn = 50, method = 'pearson'))
#5번째 사람에게 추천 영화 5개를 추천해봄
as(predict(rec, m[5,], type = 'topNList', n = 5), 'list')
