---
title: "중간점검"
subtitle: "영화 추천시스템 모델 구축"
author: "2조"
date: "`r format(Sys.Date())`"
output:
  html_document:
    fig_height: 6
    fig_width: 10
    highlight: textmate
    theme: cosmo
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    fig_height: 6
    fig_width: 10
    toc: no
  word_document:
    fig_height: 6
    fig_width: 9
    toc: no
---

데이터분석계획>상향식접근방식>비지도학습방법
: 데이터 자체의 결합, 연관성, 유사성 등을 중심으로 데이터의 상태 분석

```{r}
#save(li;st=ls(), file="0524_중간점검.RData")
#load("./data/0524_중간점검.RData")
```

## 분석환경설정
```{r, echo=T}
#setwd("./data")
#전처리에 필요한 라이브러리
library(data.table)
library(tidyverse)
library(dplyr)
library(naniar)
library(VIM)
library(DT)
library(ggplot2)
#시각화에 필요한 라이브러리
#추천알고리즘 라이브러리
library(recommenderlab)
```

## 2.데이터이해
### 2-1.데이터수집
```{r}
movies <- read.csv('./data/movies.csv',header=T) # fileEncoding='UTF-8'
ratings <- read.csv('./data/ratings.csv',header=T)
tags <- read.csv('./data/tags.csv',header=T)

#사본
m <- movies
r <- ratings
t <- tags
```

### 2-2.데이터확인
```{r}
glimpse(m)
glimpse(r)
glimpse(t)
```

#### movies.csv
```{r}
summary(m)

# 결측치 확인
which(!complete.cases(m)) 
sum(is.na(m)); sum(!is.na(m))
# 이상치 확인
# 중복값 확인
sum(duplicated(m))

m$title <- as.factor(m$title)
m$genres <- as.factor(m$genres)
summary(m)
```

```{r}
#결측치 요약 및 시각화
naniar::miss_case_summary(m) # case : 행 기준
naniar::miss_var_summary(m)  # variable : 변수 기준
naniar::gg_miss_var(m)
#VIM::aggr(m)
```

#### ratings.csv
```{r}
summary(r)

# 결측치 확인
which(!complete.cases(r)) 
sum(is.na(r)); sum(!is.na(r))
# 이상치 확인
# 중복값 확인
sum(duplicated(r))
```

```{r}
#결측치 요약 및 시각화
naniar::miss_case_summary(r) # case : 행 기준
naniar::miss_var_summary(r)  # variable : 변수 기준
naniar::gg_miss_var(r)
#VIM::aggr(m)
```

#### tags.csv
```{r}
summary(t)

# 결측치 확인
which(!complete.cases(t)) 
sum(is.na(t)); sum(!is.na(t))
# 이상치 확인
# 중복값 확인
sum(duplicated(t))

t$tag = as.factor(t$tag)
summary(t)
```

```{r}
#결측치 요약 및 시각화
naniar::miss_case_summary(t) # case : 행 기준
naniar::miss_var_summary(t)  # variable : 변수 기준
naniar::gg_miss_var(t)
#VIM::aggr(t)
```

---

## 3.데이터분석
### 3-1.분석용 데이터 준비
```{r}
r <- r[,-4]
t <- t[,-4]

#movies에 있는 장르분리 및 장르df생성
m_new <- data.table()
n <- nrow(m)
for (i in 1:n){

  #print(i)
  
  name_index <- as.character(m[i, 1])
  item_index <- as.character(m[i, 3])
  
  item_index_split_temp <- data.frame(strsplit(item_index, split = '\\|'))
  m_temp <- data.frame(cbind(name_index, item_index_split_temp))
  
  names(m_temp) <- c("movieId", "genres")
  
  m_new <- rbind(m_new, m_temp)
}
rm(name_index, item_index, item_index_split_temp, m_temp) # delete temp dataset
glimpse(m_new)
summary(m_new)

m <- m[,-3]
##m(무비) <---using key=movieId---> r(평점), t(태그), m_new(장르)
```

### 3-2.데이터 탐색(EDA) 및 전처리
  
  - 결측치, 이상치, 중복값 등을 제거
  - 추가로 요구되는 데이터 세트가 있을 시 재실행
  - 필요시 효율적으로 적용될 수 있는 데이터세트로 변환
  - 데이터분포와 변수 간의 관계파악
  - 데이터 시각화

---

#### **df = m, m_new**
```{r}
#장르확인
unique(m_new$genres)
barplot(table(m_new$genres))

#(no genres listed) -> NA 결측치 처리
m_new$genres<- gsub("\\(no genres listed\\)", NA, m_new$genres)
barplot(table(as.factor(m_new$genres)))
```

---

#### **df = m, r**
```{r}
# ##영화별 평균 평점 히스토그램
# ##try1
# df <- merge(m, r,key='movieId')
# #df <- df[,c(4,2,5)]
# df2 <- df %>% mutate(id = paste0(userId,"_", title)) 
# ##뭔가이상한데 다시확인 
# ##https://r-charting.tistory.com/9 에러관련 유니크하게 id를 만들어줘야 하나봄
# ##같은 유저가 같은 영화를 평점한 행이 존재
# sum(duplicated(df2)) #[1] 3
# which(duplicated(df2)|duplicated(df2,fromLast=T))
# df2[which(duplicated(df2)|duplicated(df2,fromLast=T)),]
# df2 <- df2[-c(78303,88673,99484,88674),]
# 
# #df_cast <- df2 %>% spread(key = "id", value = "rating", fill = 0) 
# ##memory.limit(size = 50000)
# ##https://blog.naver.com/PostView.nhn?blogId=jinis_stat&logNo=221675902841 에러관련 메모리 해결 안됨
# df_mini <- df2[1:300,c(4,2,3)]
# df_mini_cast <- spread(df_mini, key = "title", value = "rating", fill = 0)
# head(df_mini_cast)
# #hist(colMeans(df_mini_cast, na.rm = T), breaks = 50)
```

```{r}
##영화별 평균 평점 히스토그램
##try2
r2 <- r %>% group_by(movieId) %>% summarise(mean_rating = mean(rating), .groups = 'drop') 
barplot(r2$mean_rating~r2$movieId)

ggplot(data=r2,aes(x=r2$movieId,y=r2$mean_rating))+geom_point()

plot(r$movieId, r$mean_rating)
plot(r$movieId, r$mean_rating,type='l')
```


```{r}
##유저당 평점 몇개? 유저행, 평점열, 무비아이디 당 
# r<-r[,c(1,3)]
# hist(apply(r, 1, function(x) sum(!is.na(r))), breaks = 50,
#      main="개인당 평점을 매긴 영화갯수")
```

```{r}
#영화별 평점
head(r)
df <- r %>% group_by(movieId) %>% summarise(mean_rating = mean(rating))
r2 <- as.data.frame(r2)

plot(r2$movieId,r2$mean_rating) #
hist(r2[,2], main = colnames(r2)[1], breaks = 50, xlab = "평점")
```

```{r}
#유저당 평점 갯수
# df <-r %>% summarise(count_rating = n(userId))
# count(r$userId[1])
# barplot(table(r$userId))#다운샘플링 ? 
```

---

#### **df = t**
```{r}
barplot(table(t$tag))
#unique(t$tag)

#영화별 태그 
df <- t %>% group_by(userId) %>% mutate(tag=tag)
head(df)
```

```{r}
# tag 텍스트마이닝
t2 <- tolower(t$tag)
head(t2)
str(t2)
library(multilinguer)
#library(KoNLP)
library(RColorBrewer)
library(wordcloud)

sort(t2, decreasing = T) #정렬
#table(t2)
t3 <- table(t2)
palete <- brewer.pal(7,"Set3")
wordcloud(names(t3),
          freq=t3, 
          scale=c(10,1),
          rot.per=0.1,
          min.freq=15,
          random.order=F,
          random.color=T,
          colors=palete)
#legend(0.3,1 ,"tag 빈도 탐색", cex=0.9,fill=NA ,border=NA,bg="white",text.col="black",text.font=2,box.col="red")

best_tag <- c('atmospheric','funny','superhero','surreal','thought-provoking','disney','action','crime','music','comedy','sci-fi','suspense','quirky','religion','dark','aliens','dark comdey')
```

참고

https://statkclee.github.io/text/nlp-president-dtm.html
https://eda-ai-lab.tistory.com/525

---

## 4.데이터분석2
### 4-1.모델링
  - 학습용 데이터, 평가용 데이터 세트로 분리하여 과적합 방지
  - 분석 목적에 맞는 분석기법, 알고리즘 선택
  - 다양한 모델링 기법과 알고리즘을 선택하고 파라미터를 최적화
  
```{r}
#sparse(NA가 많은)한 데이터를 R에서 잘 다룰 수 있도록 데이터 타입 변경
m <- as.data.frame(m)
m$movieId <- as.integer(m$movieId)
df <- merge(m, r, key='movieId', all.y=T)
df <- df[,-1]

sum(duplicated(df)) #[1] 3
which(duplicated(df)|duplicated(df,fromLast=T))
df[which(duplicated(df)|duplicated(df,fromLast=T)),]
df <- df[-which(duplicated(df)|duplicated(df,fromLast=T)),]
df <- df[-c(80209,88669),]

df_cast <- spread(df, key = "title", value = "rating", fill = 0)
df_cast <- df_cast[,-1]
df_cast2 <- as(df_cast, 'matrix') #매트릭스로 바꿔주고
df_cast2 <- as(df_cast2, 'realRatingMatrix') #데이터타입변경

```

```{r}
#colMeans(df_cast)
hist(colMeans(df_cast))
hist(getRatings(df_cast), main="모든 사용자의 평점 빈도")
summary(getRatings(df_cast))

#표준화, 평균빼기를 통해 상관계수, 코사인 유사도 정확도 업
normalize(df_cast, method="center") #평균값을 빼줌

#각 사용자의 평점을 각 사용자별로 평균을 빼준 뒤 (mean centering) 평점 알아보기
hist(getRatings(normalize(df_cast, method='center')), main="평점-평균")
summary(getRatings(normalize(df_cast, method='center')))

#각 사용자의 평점을 각 사용자별로 표준화 한 뒤 평점 알아보기
hist(getRatings(normalize(df_cast, method = 'Z-score')), main="표준화")
summary(getRatings(normalize(df_cast, method = 'Z-score')))
```
차이를 모르겠다.

### 4-2.모형평가
  - 평가용 데이터 세트를 이용하여 모델 검증 작업
  
```{r}
#평점을 기준으로 여러 모형들의 정확도 평가
scheme <- evaluationScheme(df_cast, method="split", train = .8, k = 1, given = 3) 

algorithms <- list(
  "random" = list(name="RANDOM"),
  "popular" = list(name="POPULAR"),
  "popularZ" = list(name="POPULAR", param=list(normalize = "Z-score")),
  "userZ50C" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 50, method = 'cosine')),
  "userZ50P" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 50, method = 'pearson')),
  "itemZ100PF" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'pearson', normalize_sim_matrix = F)),
  "itemZ100PT" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'pearson', normalize_sim_matrix = T)),
  'SVDZ10PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 10)),
  'SVDZ10CF' = list(name="SVD", param=list(normalize = 'Z-score', k = 50)),
  'SVDZ50PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 100))
)

results <- evaluate(scheme, algorithms, type='ratings')

for(i in names(results)){
  
  print(i)
  print(getConfusionMatrix(results[[i]]))
}

plot(results)
#par(mfrow=c(1,1))
```

### 4-3.최종모델
  - 검증된 최종 모델을 적용하고 최적화하여 운영할 수 있는 방안 수립
  
```{r}
```


```{r}
```



