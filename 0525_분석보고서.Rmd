---
title: <center> <strong> 🎥영화 추천시스템 모델 구축 및 구현 </strong> </center>
subtitle: <p align="right"> [Analysis Report] </p>
author: <p align="right"> 2조 (김소희,김영주,유수진,유용빈) </p>
date: <p align="right"> `r format(Sys.Date())` </p>
output:
  html_document:
    theme: cosmo
    highlight: textmate
    toc: yes
    toc_depth: 4
    toc_float: yes
    number_sections: true
    #code_folding: hide
    df_print: paged
    mainfont: NanumMyeongjo
  html_notebook: default
editor_options: 
  chunk_output_type: console
---

<style type="text/css">

h1.title {
  font-size: 36px;
  color: DarkRed;
}

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T, fig.align = "center", message=F, warning=F, fig.height = 6, fig.width = 5,cache=T, dpi = 300, dev = "png")
```

**📃Description**

**📃memo** 

- Code File 구조
  (1) movies_확인_0525.R
  (2) movies_탐색_0525.R
  (3) ratings_탐색_0525.R
  (4) tags_탐색_0525.R
  (5) movies_최종데이터구축_0525.R
  (6) movies_모델링_0525.R - 평점기반
  (7) movies_모델링2_0525.R - 장르기반
</br>
- Code2 File 구조
  (1) 전처리보고서.Rmd
  (2) 분석보고서.Rmd
  
---

# 추천시스템 모델링: mr dataset

## 분석환경설정
```{r}
library(data.table)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(caret)
library(recommenderlab)
#help(package="recommenderlab")

m <- read.csv("./data/movies.csv", header=T)
r <- read.csv("./data/ratings.csv", header=T)
t <- read.csv("./data/tags.csv", header=T)
g <- read.csv("./data/genres.csv", header=T)

mr <- read.csv("./data/mr.csv", header=T)
final_mr <- spread(mr, key = "title", value = "rating", fill = NA)
final_mr <- final_mr[,-1]

knitr::kable(head(mr))
#knitr::kable(head(mr[order(mr$userId),]))
#knitr::kable(head(mr[order(mr$rating),]))
knitr::kable(table(r$rating))

df <- as(final_mr, 'matrix') 
df <- as(df, 'realRatingMatrix')
```
첫 번째 테이블은 본 모델링 작업에 사용할 데이터 내용물

두 번째 테이블은 평점분포를 대략적으로 알 수 있다.

recommenderlab 라이브러리는 realRatingMatrix 형식을 사용하기 때문에 데이터 형식을 변환해준다.



## movie - rating
  - 분석 데이터 : 'mr' dataset
  - 분석 기법 : 사용자 평점을 이용한 사용자 기반 협업 필터링 알고리즘(UBCF)을 생각하였고, 더 나은 성능을 보이는 알고리즘도 함께 평가하여 최종 모델(알고리즘)을 결정하고자 함.

### 어떻게 나오는지 확인1
```{r}
set.seed(2021)
index <- sample(1:nrow(df), size = nrow(df)*0.7)

train <- df[index, ]
test  <- df[-index,]

model1 <- Recommender(train, method = "UBCF")
model1

pre <- predict(model1, newdata=test[1], n=10) #test 1 ~ 183
# as(pre, "list")

# just check
pre_list <- sapply(pre@items, function(x) {colnames(train)[x]})
table(unlist(lapply(pre_list, length)))
knitr::kable(pre_list[])
```
데이터를 7:3 비율로 train 과 test 데이터셋으로 분할한다.
먼저 파라미터를 신경 쓰지 않고 간단한 사용자 기반의 추천 시스템 모델링을 구현해봄. 구현된 모형 model1을 가지고 추천 영화 10개를 출력한다. - 리스트를 벡터에 담아서 워드클라우드로 시각화해보자.

### 어떻게 나오는지 확인2 실행x

  - 추천시스템에 사용되는 모델 즉, 여러 알고리즘과 각 알고리즘에 파라미터 튜닝에 관하여
```{r, eval=F}
## 1 (학습 단계)
################
model1 <- Recommender(train, method = 'POPULAR') #평점이 높은 영화 순(인기순)으로 추천
model2 <- Recommender(train, method = 'POPULAR', param=list(normalize = 'Z-score')) #평점 데이터를 사용자별로 표준화
model3 <- Recommender(train, method='UBCF', param=list(method='pearson')) #피어슨 상관계수를 이용하여 추천
model4 <- Recommender(train, method='UBCF', param=list(method='cosine')) #코사인 유사도를 이용하여 추천
model5 <- Recommender(m, method='UBCF', param=list(method='cosine', nn=50)) #특정 사용자와 인접한 이웃의 수를 50으로 설정

model6 <- Recommender(m, method = "IBCF", param=list(method = 'pearson'))
model7 <- Recommender(m, method = "IBCF", param=list(method = 'pearson', normalize_sim_matrix = T)) #유사도를 행별로 normalize(행별로 유사도 합이 1이 되도록 재조정) 한 후 피어슨 상관계수를 이용하여 추천
model8 <- Recommender(m, method = "IBCF", param=list(method = 'cosine', normalize_sim_matrix = T, k=5))

## 차원 축소를 이용한 영화 추천
model9 <- Recommender(train, method = "SVD", param=list(k = 10)) #10개의 차원으로 축소
model10 <- Recommender(train, method = "SVD", param=list(k = 20, normalize='Z-score')) #20개의 차원으로 축소



## 2 (추천 단계)
################
#1번(첫번째) 사람에 대해 평점 예측
who <- 1
as(predict(model1, m[who, ], type = 'ratings'), 'list')

#1번(첫번째) 사람에 대해 평점을 예측후 평점이 높은 영화 5개만 추천
as(predict(model1, m[who, ], type = 'topNList', n=5), 'list')



#Explain
################
#Collaborative Filtering 조정할 수 있는 파라미터보기
#recommenderRegistry$get_entry(method = 'UBCF')
#recommenderRegistry$get_entry(method = 'IBCF')

#SVD 에서 조정할 수 있는 파라미터
#recommenderRegistry$get_entry(method = 'SVD')
```
위 알고리즘들은 반복되서 사용될 것이기 때문에 사용자정의함수로 정의해 놓는다.

### 평가할 알고리즘 함수 정의
```{r}
algorithms <- list(
  
  "random"  = list(name="RANDOM"),
  "popular" = list(name="POPULAR"), 
  "popularZ" = list(name="POPULAR", param=list(normalize = "Z-score")),
  
  "userN10C" = list(name="UBCF", param=list(normalize = NULL, nn = 10, method = 'cosine')),
  "userN50C" = list(name="UBCF", param=list(normalize = NULL, nn = 50, method = 'cosine')),
  "userC50C" = list(name="UBCF", param=list(normalize = 'center', nn = 50, method = 'cosine')),
  "userZ50C" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 50, method = 'cosine'))
  
  # "userN10P" = list(name="UBCF", param=list(normalize = NULL, nn = 10, method = 'pearson')), #오류
  # "userN50P" = list(name="UBCF", param=list(normalize = NULL, nn = 50, method = 'pearson')), #오류
  # "userC50P" = list(name="UBCF", param=list(normalize = 'center', nn = 50, method = 'pearson')), #오류
  # "userZ50P" = list(name="UBCF", param=list(normalize = 'Z-score', nn = 50, method = 'pearson')) #오류
)

algorithms2 <- list(
  
  'SVDZ10PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 10)),
  'SVDZ50PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 50)),
  'SVDZ100PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 100))
)
```
random, popular, ubcf, svd, ibcf를 사용. normalize, nn, method, k 옵션 등이 있다.

각 알고리즘의 개념정도와 갑 옵션의 의미 찾기.

algorithms: n을 어느정도 봐야할까. 그리고 피어슨은 에러있음. not-yet-implemented method for <dgCMatrix> %*% <list> 피어슨은 개별로 되는지 확인필요.

### 추천 시스템에서의 모형 선택 (평점기준)
```{r}
#모형 평가를 위해서 Traing Set과 Test Set 분할
set.seed(2021)
scheme <- evaluationScheme(df, method="split",
                           train = .8, k = 3, given = 15) 
#k: 심플하게 k를 여러번 할수록 잘 섞인다.
#given: 특정 정보에 편향되지 않게, 최소한 영화를 15개 본 유저정보를 활용하겠다.
scheme@runsTrain

#Training Set으로 각 알고리즘에 대해서 학습 후 Test Set을 이용하여 정확도 평가
results <- evaluate(scheme, algorithms, type='ratings')
results2 <- evaluate(scheme, algorithms2, type='ratings')

#각 모형에 대한 정확도 확인
names(results)
names(results2)

for (i in names(results)){
  
  print(i)
  print(getConfusionMatrix(results[[i]]))
}

for (i in names(results2)){
  
  print(i)
  print(getConfusionMatrix(results2[[i]]))
}

#각 모형에 대한 정확도 시각화
plot(results, annotate=1, legend="topleft")
plot(results2, annotate=1, legend="topleft")
```

### 추천 시스템에서의 모형 선택 (추천목록기준)
  - 추천목록기준?? evaluate에 들어가는 n 의미무엇?
  
```{r}
#모형 평가를 위해서 Traing Set과 Test Set 분할하기: 
#단, 3점 이상일 경우 재미있게 봤다고 가정
set.seed(2021)
scheme <- evaluationScheme(df, method="split",
                           train = .8, k = 1, given = 15, goodRating = 3)

#Training Set으로 각 알고리즘에 대해서 학습 후 Test Set을 이용하여 정확도 평가
results <- evaluate(scheme, algorithms, type='topNList', n=c(1, 3, 5, 10, 15, 20))

#각 모형에 대한 정확도 확인
names(results)

for (i in names(results)){
  
  print(i)
  print(getConfusionMatrix(results[[i]]))
}

#정확도 결과 그래프로 나타내기
plot(results, annotate=1, legend="topleft")
```
이를 통해 최종알고리즘 결정


### 유사도는 어떻게 계산되고 있을까 (탐색)
```{r}
# 유사도
similarity_mat <- similarity(train[1:10,], method = "cosine", which = "users")
as.matrix(similarity_mat)
image(as.matrix(similarity_mat), main = "user's similiarity")

# 히트맵
image(train[1:30,1:30], axes=FALSE, main = "10 x 10 heatmap")

# top
movie_ratings <- train[rowCounts(train) > 50, colCounts(train) > 50]
movie_ratings

minimum_movies <- quantile(rowCounts(movie_ratings), 0.98)
minimum_users <- quantile(colCounts(movie_ratings), 0.98)
image(movie_ratings[rowCounts(movie_ratings) > minimum_movies,
                    colCounts(movie_ratings) > minimum_users],
      main = "Heatmap of the top users and movies")


## 데이터..
# qplot(table(r$rating), fill=I("steelblue"), col=I("red")) +
#   ggtitle("A distribution of the average rating per user")

# heatmap of normalized value
# image(normalized_ratings[rowCounts(normalized_ratings) > minimum_movies,
#       colCounts(normalized_ratings) > minimum_users],
#       main = "Normailized ratings of the top users")

```



### 추천 시스템에서의 모형 선택 (데이터 조정 후 재학습) 아직 실행 X
```{r, eval=F}
# 데이터 조정 후 재학습
table(rowCounts(df))
mean(rowCounts(df))
data_modify <- df[rowCounts(df) <= 165.2918]
dim(data_modify)
boxplot(Matrix::rowMeans(data_modify), horizontal=T)



# "split", cross val.
set.seed(2021)
scheme <- evaluationScheme(data_modify, method="split",
                           train = .8, k = 3, given = 15) 

results <- evaluate(scheme, algorithms, type='ratings')
results2 <- evaluate(scheme, algorithms2, type='ratings')

plot(results, annotate=1, legend="topleft")
plot(results2, annotate=1, legend="topleft")




# 최종 알고리즘 결정 된 것에 대하여 
model1 <- Recommender(train, method = 'POPULAR')
pre <- predict(model1, newdata=test[1], n=10) #test 1 ~ 183
# as(pre, "list")

# just check
pre_list <- sapply(pre@items, function(x) {colnames(train)[x]})
table(unlist(lapply(pre_list, length)))
knitr::kable(pre_list[])


# split, "cross val."
eval_sets <- evaluationScheme(data = data_modify,
                              method = "cross-validation",
                              train = 0.7,
                              k = 10,
                              goodRating = 3,
                              given = 10)

n_recommendations = c(1,5,seq(10,100,10))

# Training dataset modeling
model1 <- Recommender(data = getData(eval_sets, "train"),
                           method = "UBCF", 
                           parameter = NULL)
model1

# Prediction
pred_eval <- predict(model1, 
                     newdata = getData(eval_sets, "known"),
                     n = 10, type = "ratings")
pred_eval


# Calculate accuracy
accuracy_model1 <- calcPredictionAccuracy(x=pred_eval,
                                        data=getData(eval_sets, "unknown"),
                                        byUser=T)
head(accuracy_model1, 10)
colMeans(accuracy_model1)

# Calculate accuracy 2
# ?evaluate
algorithms <- list(
  
  RANDOM = list(name = "RANDOM", param = NULL),
  POPULAR = list(name = "POPULAR", param = NULL),
  HYBRID = list(name = "HYBRID", param =
      list(recommenders = list(
        RANDOM = list(name = "RANDOM", param = NULL),
        POPULAR = list(name = "POPULAR", param = NULL))))
)
result <- evaluate(eval_sets, algorithms, n=n_recommendations)
result
avg(result) #precision(정밀도), recall(재현율)



plot(result, annotate=T, legend="right", main = "ROC Curve")
plot(result, "prec/rec", annotate=T,legend="right") #bad.. 
# plot(result2, annotate=T, legend="topleft")
# plot(result2, "prec/rec", annotate=T,legend="topleft")

#따로 평가해서 result값 넣은 후 비교
#정밀도 재현율 곡선 해설 find
```

> 함수설명

[evaluationScheme](https://www.rdocumentation.org/packages/recommenderlab/versions/0.2-7/topics/evaluationScheme)

[HybridRecommender](https://rdrr.io/cran/recommenderlab/man/HybridRecommender.html)

![k-fold CV](./img/k-fold.png)
![ROC Curve](./img/roc.png)
[ROC EXPLAIN LINK1](https://newsight.tistory.com/53)
[ROC EXPLAIN LINK2](https://angeloyeo.github.io/2020/08/05/ROC.html)

---

# 추천시스템 모델링: mg dataset
```{r, warning=F}
mg <- read.csv('./data/mg.csv', header=T)
final_mg <- spread(mg, key = "genres", value = "value", fill = NA)
final_mg <- final_mg[,-c(1,2)]
```

```{r}
knitr::kable(head(mg))
knitr::kable(table(mg$genres))

df2 <- as(final_mg, 'matrix') 
df2 <- as(df2, 'realRatingMatrix')
```

## 분석환경설정
  - 분석 데이터 : 'mg' dataset
  - 분석 기법 : 영화 자체 정보를 이용한 아이템 기반 협업 필터링 알고리즘(IBCF)

### 평가할 알고리즘 함수 정의
```{r, eval=F}
algorithms <- list(
  
  "random"  = list(name="RANDOM"),
  "popular" = list(name="POPULAR"), 
  "popularZ" = list(name="POPULAR", param=list(normalize = "Z-score")),
  
  "itemZ100PF" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'pearson', normalize_sim_matrix = F)),
  "itemZ100PT" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'pearson', normalize_sim_matrix = T)),
  "itemZ100CF" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'cosine', normalize_sim_matrix = F)),
  "itemZ100CT" = list(name="IBCF", param=list(normalize = 'Z-score', k = 100, method = 'cosine', normalize_sim_matrix = T)),
  "itemZ500PT" = list(name="IBCF", param=list(normalize = 'Z-score', k = 500, method = 'pearson', normalize_sim_matrix = T)),
  "itemZ500CT" = list(name="IBCF", param=list(normalize = 'Z-score', k = 500, method = 'cosine', normalize_sim_matrix = T)),
  
  'SVDZ10PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 10)),
  'SVDZ50PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 50)),
  'SVDZ100PT' = list(name="SVD", param=list(normalize = 'Z-score', k = 100)),
)
```

```{r, eval=F}
set.seed(2021)
index <- sample(1:nrow(df2), size = nrow(df2)*0.7)

train <- df2[index, ]
test  <- df2[-index,]

model1 <- Recommender(train, method = "IBCF")
model1

pre <- predict(model1, newdata=test[1], n=10) #test 1 ~ 183
# as(pre, "list")

# just check
pre_list <- sapply(pre@items, function(x) {colnames(train)[x]})
table(unlist(lapply(pre_list, length)))
knitr::kable(pre_list[])
```


```{r, eval=F}
# 데이터 조정 후 재학습
table(rowCounts(df2))
mean(rowCounts(df2))
data_modify <- df2[rowCounts(df2) <= 2.266886]
dim(data_modify)

boxplot(Matrix::rowMeans(data_modify), horizontal=T)
# 아IBCF 알고리즘으로는 장르기반 별로?

eval_sets <- evaluationScheme(data = data_modify,
                              method = "cross-validation",
                              train = 0.7,
                              k = 3,
                              #goodRating = 3,
                              given = 1)

n_recommendations = c(1,5,seq(10,100,10))

# Training dataset modeling
model1 <- Recommender(data = getData(eval_sets, "train"),
                           method = "IBCF", 
                           parameter = NULL)
model1

# Prediction
pred_eval <- predict(model1, 
                     newdata = getData(eval_sets, "known"),
                     n = 10, type = "ratings")
pred_eval
```

```{r, eval=F}
# Calculate accuracy
accuracy_model1 <- calcPredictionAccuracy(x=pred_eval,
                                        data=getData(eval_sets, "unknown"),
                                        byUser=T)
head(accuracy_model1, 10)
colMeans(accuracy_model1)

# Calculate accuracy 2
# ?evaluate
algorithms <- list(
  
  RANDOM = list(name = "RANDOM", param = NULL),
  POPULAR = list(name = "POPULAR", param = NULL),
  HYBRID = list(name = "HYBRID", param =
      list(recommenders = list(
        RANDOM = list(name = "RANDOM", param = NULL),
        POPULAR = list(name = "POPULAR", param = NULL))))
)
result <- evaluate(eval_sets, algorithms, n=n_recommendations)
result
avg(result) #precision(정밀도), recall(재현율)
```

```{r, eval=F}
plot(result, annotate=T, legend="right", main = "ROC Curve")
plot(result, "prec/rec", annotate=T,legend="right") #bad.. 
# plot(result2, annotate=T, legend="topleft")
# plot(result2, "prec/rec", annotate=T,legend="topleft")

#따로 평가해서 result값 넣은 후 비교
#정밀도 재현율 곡선 해설 find
```


---


### 추천영화 시각화
  - 사용자기반(평점)
  
```{r}
n=300
pre <- predict(model1, newdata=test[2], n) #test 1 ~ 183
min_rating <- min(pre@ratings[[1]])
max_rating <- max(pre@ratings[[1]])
e_value <- (max_rating-min_rating)/10

# just check
pre_list <- sapply(pre@items, function(x) {colnames(train)[x]})
pre_ratings <- pre@ratings[[1]]
for(i in 1:n){
  if(pre_ratings[i] <= max_rating && pre_ratings[i] > max_rating-e_value){
    pre_ratings[i] <- 100 #가중치 100
  }else if(pre_ratings[i] <= max_rating-e_value && pre_ratings[i] > max_rating-e_value*2){
    pre_ratings[i] <- 90 #가중치 90
  }else if(pre_ratings[i] <= max_rating-e_value*2 && pre_ratings[i] > max_rating-e_value*4){
    pre_ratings[i] <- 70 #가중치 70
  }else if(pre_ratings[i] <= max_rating-e_value*4 && pre_ratings[i] > max_rating-e_value*6){
    pre_ratings[i] <- 50 #가중치 50
  }else{
    pre_ratings[i] <- 25
  }
}

table(unlist(lapply(pre_list, length)))
knitr::kable(pre_list[])
# 
library(RColorBrewer)
library(wordcloud)
pre_vec <- c(pre_list)
pre_vec <- as.data.frame(pre_vec)
pre_vec[ , "freq" ] <- c(pre_ratings)
set.seed(1234)
par(bg="black")
pal<- brewer.pal(7,"YlOrRd")
wordcloud(words = pre_vec$pre_vec, # 단어 
                         freq = pre_vec$freq, # 빈도
                         min.freq = 25, # 최소 단어 빈도
                         max.words = 300, # 표현 단어 수 
                         random.order = F, # 고빈도 단어 중앙 배치
                         rot.per = 0, # 회전 단어 비율 
                         scale = c(1, 0.25), # 단어 크기 범위
                         colors = pal) # 색깔 목록


```





# 군집화 분석: 장르

  - 데이터셋: 영화 장르 정보
  - 분류알고리즘: k-means, 계층적군집법, min-hash
  - 유사도: cosine similarity, Jaccard, Euclidean

## 유저/장르/평점

```{r}
head(m)
head(r)
```
각 유저(userId)에 대하여 무슨 장르를 선호하는지 (평균평점을)계산하고, 그 정보로 **유저 간 유사도**를 바탕으로 클러스터링을 진행

movies데이터에는 영화id/제목/장르로 구성되어 있고 평점 정보가 있는 rating데이터는 유저id/영화id/평점/시간정보로 구성되어 있다. 

```{r, eval=FALSE}
user_genres <- merge(m, r, key='movieId', all.y=T)
user_genres2 <- data.table()
n <- nrow(user_genres)
for (i in 1:n){
  
  #print(i)
  
  name_index <- as.character(user_genres[i, 1])
  item_index <- as.character(user_genres[i, 3])
  userId <- as.character(user_genres[i, 4])
  rating <- as.character(user_genres[i, 5])
  
  item_index_split_temp <- data.frame(strsplit(item_index, split = '\\|'))
  m_temp <- data.frame(cbind(name_index, item_index_split_temp, userId, rating))
  
  names(m_temp) <- c("movieId", "genres", "userId", "rating")
  
  user_genres2 <- rbind(user_genres2, m_temp)
}
rm(name_index, item_index, item_index_split_temp, m_temp)
user_genres2$rating <- as.numeric(user_genres2$rating)
user_genres2$genres <- gsub("\\(no genres listed\\)", "Unknown", user_genres2$genres)
user_genres2 <- as.data.frame(user_genres2)
glimpse(user_genres2)
#write.csv(user_genres2, "./data/user_genres.csv",row.names = F)
```
클러스터링을 위해 각 유저에 대하여 장르별 평균평점을 계산하여 데이터셋을 구축한다.
  - 장르 분리
  - 유저별 장르 평균평점 계산

### 유저별 장르 평균평점 계산
```{r}
user_genres2 <- read.csv("./data/user_genres.csv", header=T)
glimpse(user_genres2)

ug <- user_genres2 %>% group_by(userId, genres) %>% mutate(mean_rating=mean(rating))
ug <- spread(ug, key = "genres", value = "mean_rating", fill = 0)
ug <- ug[,-c(1,3)]
knitr::kable(head(ug))
```
클러스터링 유사도
  - 유클리디안: 각 유저ID의 장르별 평점을 Feature로 간주하여, 말그대로 유클리드 거리를 계산하여 비슷한 유저끼리 묶는 방법
  - 코사인: 각 유저ID의 장르별 평점을 Feature로 간주하여, 각 유저ID간 벡터의 각도가 비슷한 유저를 묶는 방법

결과:
유클리드 기반의 ward 계산을 통해 3개의 그룹으로 분류

---

hclust()

method : 클러스터와 관측치와의 거리 계산 기준 
  - single : 최단거리법
  - complete : 최장거리법, 완전기준법 
  - average : 평균기준법 
  - median : 중앙중심법 

```{r}
### numeric data - default 유클리드(euclidean)거리
# d1 <- dist(ug)
# m1 <- hclust(d1, method = 'average')
# m2 <- hclust(d1, method = 'complete')
# m3 <- hclust(d1, method = 'single')
# m4 <- hclust(d1, method = 'median')
# m5 <- hclust(d1, method = 'ward.D')

#plot(m1, hang = -10) # hang : 관측치를 맞춰주기 위한 옵션
#rect.hclust(m1, k = 19) # 클러스터를 k 기준으로 군집
```

```{r}
# 1. 거리행렬 구하기
ug_scaled <- scale(ug[-1]) # 거리 기반이므로 표준화 필요 
d1 <- dist(ug_scaled[1:10,])
as.matrix(d1)[1:4,]

# 2. 거리행렬 모델 적용(계층적 군집화)
fit <- hclust(d1, method="average")  # method의 종류보다는 어떤 의도 하에 분류할 것인지에 따라 설명변수를 선택하는 것이 중요
plot(fit, hang=-1 , cex=0.8)

# 군집 수 설정
# library(NbClust)
# nc <- NbClust(ug[1:10,], distance="euclidean", method="average")

clusters <- cutree(fit, k=5)
table(clusters)     # 군집별 데이터 개수 확인
rect.hclust(fit, k=5) 
```



## 영화/장르 벡터화
  - 목적: 영화 분류?
  - 분류알고리즘: k-means, knn?
  - 유사도: cosine
  
```{r}
mg <- read.csv("./data/mg.csv", header = T)
final_mg <- spread(mg, key = "genres", value = "value", fill = 0)
final_mg <- final_mg[,-1]
```

```{r}
### binary data
# dist(final_mg[,-1], method="binary")
# dist(final_mg[,-1], method = "Jaccard")

kmeans.mg <- kmeans(final_mg[,-1],3,nstart=5)
round(sum(kmeans.mg$withinss),2) 
#kmeans.mg$cluster <- as.factor(kmeans.mg$cluster)
a=kmeans.mg$cluster
b=kmeans.mg$center

library(fpc)
plotcluster(final_mg[-1], a, main = 'k - 평균 군집')

```

[참고](https://velog.io/@yuhayung7296/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5-%EA%B8%B0%EB%B2%95%EC%9D%B8-%EA%B5%B0%EC%A7%91%EB%B6%84%EC%84%9Dclustering-%EA%B8%B0%EB%B2%95-in-R)


# 연관성 분석: 장르, 태그

  - EDA: 평점 분포, 품사 별 긍부정 분포
  - word2vec을 활용한 워드임베딩
  - K-means를 활용한 군집화
  - 이외에 전처리나 WordCloud

---

# 고려사항

  - 패키지 내 다양한 함수들을 보다 적절하게 사용하기 위해 이론 학습은 필요하다.

  - 위 패키지는 지속적으로 업그레이드가 되고 있기 때문에 [Reference Manual](https://cran.r-project.org/web/packages/recommenderlab/recommenderlab.pdf)을 활용한다.

---

# 문제점

---

# 희망사항

  - R과 R shiny를 활용한 추천시스템 구현
  - sample: https://andreasvoglstatworx.shinyapps.io/apptest/

---

**📃참고**

  - http://statkclee.github.io/parallel-r/recommendation-sparklyr.html
  - https://rstatistics.tistory.com/31#- 
  - [R 색상표](https://rfriend.tistory.com/150)
  - [장르 상관관계를 사용한 영화추천 알고리즘](https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002625066)




